{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries\n",
    "First, we need to import the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, precision_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Preview the Data\n",
    "Load the dataset and take a quick look at the first few rows, the data info, and descriptive statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Descriptive statistics:\n",
      "       customer_id_int      Recency    Frequency     Monetary  recency_score  \\\n",
      "count      1000.000000  1000.000000  1000.000000   1000.00000     1000.00000   \n",
      "mean        500.500000    35.354000    10.000000  24877.57597        3.02700   \n",
      "std         288.819436    33.996742     3.076925   9002.90459        1.41855   \n",
      "min           1.000000     1.000000     1.000000    451.58000        1.00000   \n",
      "25%         250.750000    10.750000     8.000000  18597.53000        2.00000   \n",
      "50%         500.500000    24.000000    10.000000  24264.98000        3.00000   \n",
      "75%         750.250000    51.000000    12.000000  30731.06000        4.00000   \n",
      "max        1000.000000   260.000000    24.000000  53896.74000        5.00000   \n",
      "\n",
      "       frequency_score  monetary_score           R            F            M  \\\n",
      "count      1000.000000     1000.000000  1000.00000  1000.000000  1000.000000   \n",
      "mean          3.000000        3.000000     3.02700     2.842000     3.000000   \n",
      "std           1.414921        1.414921     1.41855     1.397494     1.414921   \n",
      "min           1.000000        1.000000     1.00000     1.000000     1.000000   \n",
      "25%           2.000000        2.000000     2.00000     2.000000     2.000000   \n",
      "50%           3.000000        3.000000     3.00000     3.000000     3.000000   \n",
      "75%           4.000000        4.000000     4.00000     4.000000     4.000000   \n",
      "max           5.000000        5.000000     5.00000     5.000000     5.000000   \n",
      "\n",
      "         RFM_Score  \n",
      "count  1000.000000  \n",
      "mean      8.869000  \n",
      "std       3.325492  \n",
      "min       3.000000  \n",
      "25%       6.000000  \n",
      "50%       9.000000  \n",
      "75%      12.000000  \n",
      "max      15.000000  \n"
     ]
    }
   ],
   "source": [
    "# Load and preview the data\n",
    "file_path = './loan_rfm.csv'  # Update path as needed\n",
    "df = pd.read_csv(file_path)\n",
    "# print(\"Data preview:\\n\", df.head())\n",
    "# print(\"\\nData info:\")\n",
    "# print(df.info())\n",
    "print(\"\\nDescriptive statistics:\")\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the Target Variable\n",
    "Create a binary target variable based on the `RFM_Score`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Target variable distribution:\n",
      "target\n",
      "0    559\n",
      "1    441\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Define target variable\n",
    "df['target'] = df['RFM_Score'].apply(lambda x: 1 if x >= 10 else 0)\n",
    "print(\"\\nTarget variable distribution:\")\n",
    "print(df['target'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Features and Target\n",
    "Select the features and the target variable for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and target\n",
    "X = df[['Recency', 'Frequency', 'Monetary', 'recency_score', 'frequency_score', 'monetary_score']]\n",
    "y = df['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Split Data into Training and Test Sets\n",
    "Split the data into training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale the Features\n",
    "Standardize the features to have a mean of 0 and a standard deviation of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning with GridSearchCV\n",
    "Use GridSearchCV to find the best parameters for the logistic regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best model parameters: {'C': 10.0, 'class_weight': None, 'solver': 'lbfgs'}\n"
     ]
    }
   ],
   "source": [
    "# Initialize and train the model with improved parameters using GridSearchCV for hyperparameter tuning\n",
    "param_grid = {\n",
    "    'solver': ['lbfgs', 'liblinear'],\n",
    "    'class_weight': ['balanced', None],\n",
    "    'C': [0.1, 1.0, 10.0]\n",
    "}\n",
    "grid_search = GridSearchCV(LogisticRegression(max_iter=500), param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Best model from grid search\n",
    "best_model = grid_search.best_estimator_\n",
    "print(\"\\nBest model parameters:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation\n",
    "Evaluate the model using accuracy and precision scores, and display the classification report and confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 99.67%\n",
      "Model Precision: 99.25%\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       167\n",
      "           1       0.99      1.00      1.00       133\n",
      "\n",
      "    accuracy                           1.00       300\n",
      "   macro avg       1.00      1.00      1.00       300\n",
      "weighted avg       1.00      1.00      1.00       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make predictions and evaluate\n",
    "y_pred = best_model.predict(X_test_scaled)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "print(f\"Model Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"Model Precision: {precision * 100:.2f}%\")\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix:\n",
      "[[166   1]\n",
      " [  0 133]]\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Probability Column\n",
    "Add a column with the probability values of the logistic regression, rounded to two decimal places."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data with probability values:\n",
      "    customer_id_int  Recency  Frequency  Monetary  recency_score  \\\n",
      "0                1       48         10  14692.31              2   \n",
      "1                2        7         12  30247.14              5   \n",
      "2                3      137          7  21466.88              1   \n",
      "3                4        6         17  42961.48              5   \n",
      "4                5       34          9  24022.56              2   \n",
      "\n",
      "   frequency_score  monetary_score  R  F  M RFM_Segment  RFM_Score  target  \\\n",
      "0                3               1  2  3  1   2.03.01.0          6       0   \n",
      "1                4               4  5  4  4   5.04.04.0         13       1   \n",
      "2                1               2  1  1  2   1.01.02.0          4       0   \n",
      "3                5               5  5  5  5   5.05.05.0         15       1   \n",
      "4                2               3  2  2  3   2.02.03.0          7       0   \n",
      "\n",
      "   probability  \n",
      "0          0.0  \n",
      "1          1.0  \n",
      "2          0.0  \n",
      "3          1.0  \n",
      "4          0.0  \n"
     ]
    }
   ],
   "source": [
    "# Add a column with the probability values of the logistic regression (rounded to two decimals)\n",
    "df['probability'] = best_model.predict_proba(scaler.transform(X))[:, 1]\n",
    "df['probability'] = df['probability'].round(2)\n",
    "print(\"\\nData with probability values:\\n\", df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the Updated DataFrame\n",
    "Save the updated DataFrame to a new CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Updated data saved to 'loan_rfm_with_probabilities.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Save the updated dataframe to a new CSV file\n",
    "df.to_csv('loan_rfm_with_probabilities.csv', index=False)\n",
    "print(\"\\nUpdated data saved to 'loan_rfm_with_probabilities.csv'.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
